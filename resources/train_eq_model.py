import os
import random
import glob
import torch
import torch.nn as nn
import torch.optim as optim
import torchaudio
import torchaudio.transforms as T
import torchaudio.functional as F
from torch.utils.data import Dataset, DataLoader

# ==========================================
# [ì„¤ì •] ë°ì´í„° ê²½ë¡œë¥¼ ë³¸ì¸ í™˜ê²½ì— ë§ê²Œ ìˆ˜ì •í•˜ì„¸ìš”!
# ==========================================
MUSDB_PATH = r".\musdb18hq"  # WAV íŒŒì¼ì´ ìˆëŠ” í´ë”
SAMPLE_RATE = 22050
DURATION = 3  # í•™ìŠµí•  ê¸¸ì´ (3ì´ˆ)
BATCH_SIZE = 16
EPOCHS = 20

# ---------------------------------------------------------
# 1. AI ëª¨ë¸ ì •ì˜ (ê°€ë²¼ìš´ CNN êµ¬ì¡°)
# ---------------------------------------------------------
class MasteringAI(nn.Module):
    def __init__(self):
        super().__init__()
        # ì†Œë¦¬ë¥¼ ê·¸ë¦¼(Mel-Spectrogram)ìœ¼ë¡œ ë³€í™˜
        self.to_spec = T.MelSpectrogram(sample_rate=SAMPLE_RATE, n_mels=64)
        self.to_db = T.AmplitudeToDB()
        
        # ê·¸ë¦¼ì„ ë³´ê³  íŠ¹ì§•ì„ ì°¾ëŠ” ëˆˆ (CNN)
        self.cnn = nn.Sequential(
            nn.Conv2d(1, 16, 3, padding=1), nn.BatchNorm2d(16), nn.ReLU(),
            nn.MaxPool2d(2),
            nn.Conv2d(16, 32, 3, padding=1), nn.BatchNorm2d(32), nn.ReLU(),
            nn.MaxPool2d(2),
            nn.Conv2d(32, 64, 3, padding=1), nn.BatchNorm2d(64), nn.ReLU(),
            nn.MaxPool2d(2),
            nn.AdaptiveAvgPool2d((4, 4)) # ì–´ë–¤ ê¸¸ì´ì˜ ì˜¤ë””ì˜¤ê°€ ì™€ë„ í¬ê¸° ê³ ì •
        )
        
        # ìµœì¢… íŒë‹¨ (3ê°œì˜ EQ ê°’ ì˜ˆì¸¡)
        self.head = nn.Sequential(
            nn.Flatten(),
            nn.Linear(64 * 4 * 4, 128),
            nn.ReLU(),
            nn.Linear(128, 3) # [Low, Mid, High]
        )

    def forward(self, x):
        spec = self.to_db(self.to_spec(x))
        return self.head(self.cnn(spec.unsqueeze(1)))

# ---------------------------------------------------------
# 2. ë°ì´í„°ì…‹ ì •ì˜ (í•µì‹¬: ì†Œë¦¬ë¥¼ ê³ ì˜ë¡œ ë§ê°€ëœ¨ë¦¬ëŠ” ë¡œì§)
# ---------------------------------------------------------
class CorruptedAudioDataset(Dataset):
    def __init__(self, root_dir):
        # musdb í´ë” ë‚´ì˜ ëª¨ë“  wav íŒŒì¼ì„ ì°¾ìŠµë‹ˆë‹¤ (train/test êµ¬ë¶„ ì—†ì´ ë‹¤ ì”€)
        self.files = glob.glob(os.path.join(root_dir, "**", "*.wav"), recursive=True)
        # ë„ˆë¬´ ì§§ì€ íŒŒì¼ì´ë‚˜ ì´ìƒí•œ íŒŒì¼ ì œì™¸
        self.files = [f for f in self.files if "mixture" not in f] # mixtureëŠ” ì œì™¸í•˜ê³  ê°œë³„ ìŠ¤í…œë§Œ ì‚¬ìš©

    def __len__(self):
        return len(self.files)

    def __getitem__(self, idx):
        # 1. íŒŒì¼ ë¡œë“œ
        path = self.files[idx]
        waveform, sr = torchaudio.load(path)
        
        # 2. ìƒ˜í”Œë§ ë ˆì´íŠ¸ ë§ì¶”ê¸°
        if sr != SAMPLE_RATE:
            waveform = F.resample(waveform, sr, SAMPLE_RATE)
        
        # 3. ëª¨ë…¸ë¡œ ë³€í™˜ ë° ê¸¸ì´ ìë¥´ê¸° (3ì´ˆ)
        waveform = torch.mean(waveform, dim=0, keepdim=True)
        num_samples = SAMPLE_RATE * DURATION
        
        if waveform.shape[1] > num_samples:
            start = random.randint(0, waveform.shape[1] - num_samples)
            waveform = waveform[:, start:start+num_samples]
        else:
            # ì§§ìœ¼ë©´ íŒ¨ë”©
            waveform = torch.nn.functional.pad(waveform, (0, num_samples - waveform.shape[1]))

        # 4. [í•µì‹¬] ëœë¤ EQ ì ìš© (ì†Œë¦¬ ë§ê°€ëœ¨ë¦¬ê¸°)
        # Low Shelf (100Hz), Peaking (1000Hz), High Shelf (10000Hz)
        low_gain = random.uniform(-10.0, 10.0)
        mid_gain = random.uniform(-10.0, 10.0)
        high_gain = random.uniform(-10.0, 10.0)

        # Torchaudio í•„í„° ì ìš©
        # (ì£¼ì˜: ì‹¤ì œ í•™ìŠµ ì†ë„ë¥¼ ìœ„í•´ ì—¬ê¸°ì„  ë‹¨ìˆœí™”í–ˆìŠµë‹ˆë‹¤. ì‹¤ì œë¡  GPUì—ì„œ ëŒë¦¬ëŠ”ê²Œ ë¹ ë¦…ë‹ˆë‹¤)
        augmented = F.lowpass_biquad(waveform, SAMPLE_RATE, cutoff_freq=100, Q=0.707) # ë‹¨ìˆœí™”ë¥¼ ìœ„í•´ í•„í„° í•˜ë‚˜ë§Œ ì˜ˆì‹œë¡œ ì ìš©í•˜ê±°ë‚˜
        # ì—¬ê¸°ì„œëŠ” "ë§ê°€ì§„ ì˜¤ë””ì˜¤"ë¥¼ í‰ë‚´ë‚´ê¸° ìœ„í•´ EQê°’ì„ ì ìš©í•œ íŒŒí˜•ì„ ë§Œë“­ë‹ˆë‹¤.
        # *ì‹¤ì œ êµ¬í˜„ íŒ*: íŒŒì´ì¬ ë£¨í”„ì—ì„œ í•„í„°ë¥¼ ê±°ëŠ”ê±´ ëŠë¦¬ë¯€ë¡œ, 
        # í•™ìŠµë•ŒëŠ” "ë§ê°€ëœ¨ë ¸ë‹¤ ì¹˜ê³ " ì •ë‹µ(Target)ë§Œ ë°˜ëŒ€ë¡œ ì£¼ëŠ” ë°©ì‹ì„ ì“°ê¸°ë„ í•©ë‹ˆë‹¤.
        # í•˜ì§€ë§Œ ì •í™•ì„±ì„ ìœ„í•´ ì‹¤ì œë¡œ í•„í„°ë¥¼ ê²ë‹ˆë‹¤.
        
        corrupted = F.equalizer_biquad(waveform, SAMPLE_RATE, center_freq=100, gain=low_gain, Q=0.707)
        corrupted = F.equalizer_biquad(corrupted, SAMPLE_RATE, center_freq=1000, gain=mid_gain, Q=0.707)
        corrupted = F.equalizer_biquad(corrupted, SAMPLE_RATE, center_freq=10000, gain=high_gain, Q=0.707)

        # 5. ì •ë‹µ ë¼ë²¨ ìƒì„± (ë³µêµ¬í•˜ë ¤ë©´ ë°˜ëŒ€ë¡œ í•´ì•¼ í•¨)
        # ì˜ˆ: ì €ìŒì„ 5dB ì˜¬ë ¸ìœ¼ë©´, ë³µêµ¬í•˜ë ¤ë©´ -5dB í•´ì•¼ í•¨
        target = torch.tensor([-low_gain, -mid_gain, -high_gain], dtype=torch.float32)

        return corrupted.squeeze(), target

# ---------------------------------------------------------
# 3. í•™ìŠµ ë£¨í”„
# ---------------------------------------------------------
def train():
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"ğŸ”¥ í•™ìŠµ ì¥ì¹˜: {device}")

    # ë°ì´í„°ì…‹ ì¤€ë¹„
    dataset = CorruptedAudioDataset(MUSDB_PATH)
    dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0) # ìœˆë„ìš°ë¼ workers=0
    
    print(f"ğŸµ ë°ì´í„° ê°œìˆ˜: {len(dataset)}ê°œ")

    model = MasteringAI().to(device)
    optimizer = optim.Adam(model.parameters(), lr=0.001)
    criterion = nn.MSELoss() # ì •ë‹µ ìˆ«ìì™€ ì˜ˆì¸¡ ìˆ«ìì˜ ì°¨ì´ ê³„ì‚°

    model.train()
    for epoch in range(EPOCHS):
        total_loss = 0
        for i, (audio, target) in enumerate(dataloader):
            audio, target = audio.to(device), target.to(device)
            
            optimizer.zero_grad()
            output = model(audio) # AIì˜ ì˜ˆì¸¡ê°’
            loss = criterion(output, target) # ì •ë‹µ(ë³µêµ¬ê°’)ê³¼ì˜ ì°¨ì´
            
            loss.backward()
            optimizer.step()
            
            total_loss += loss.item()
            
            if i % 10 == 0:
                print(f"Epoch {epoch+1} | Batch {i} | Loss: {loss.item():.4f}")

        print(f"âœ… Epoch {epoch+1} ì™„ë£Œ! í‰ê·  Loss: {total_loss / len(dataloader):.4f}")
        
        # ëª¨ë¸ ì €ì¥
        torch.save(model.state_dict(), "model2_mastering.pth")

if __name__ == "__main__":
    train()